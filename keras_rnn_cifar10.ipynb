{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_rnn_cifar10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valentinocc/Keras_cifar10/blob/master/keras_rnn_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxkRJkPl8Q-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "0e0a1c92-7165-4c0e-a17e-a853e5e41eb6"
      },
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.33.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.16.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (3.0.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (0.15.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0UvsBKarT2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, Activation, add, MaxPooling2D, Dense, Flatten, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "%load_ext tensorboard.notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjETuecY8XNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def residual_block(x, filter_amount, project=False):  \n",
        "\n",
        "  if (project):#project x_input to the new dimensions\n",
        "    x_input = MaxPooling2D(pool_size = (2, 2), strides = (2, 2))(x)\n",
        "    x_input = Conv2D(filter_amount, (1, 1), strides = (1, 1), padding = 'same')(x_input)\n",
        "    x = conv_elu_block(x, filter_amount, strides = (2, 2))\n",
        "    \n",
        "  else:\n",
        "    x_input = x\n",
        "    x = conv_elu_block(x, filter_amount)\n",
        "  \n",
        "  x = conv_elu_block(x, filter_amount)\n",
        "  \n",
        "  residual_block = add([x, x_input])\n",
        "  \n",
        "  \n",
        "  return residual_block\n",
        "  \n",
        "  \n",
        "  \n",
        "def conv_elu_block(x, filter_amount, strides = (1,1)):\n",
        "  \n",
        "  x = Conv2D(filter_amount, (3, 3), strides = strides, padding = 'same')(x)\n",
        "  x = Activation('elu')(x)\n",
        "  \n",
        "  return x\n",
        "\n",
        "\n",
        "def residual_neural_network(image_input, stack_amount, class_amount):\n",
        "    \n",
        "  x = Conv2D(16, (3, 3), strides = (1, 1), padding = 'same')(image_input)\n",
        "  \n",
        "  for i in range(stack_amount):\n",
        "    x = residual_block(x, 16)\n",
        "  \n",
        "  x = residual_block(x, 32, project=True)\n",
        "  \n",
        "  for i in range(stack_amount):\n",
        "    x = residual_block(x, 32)\n",
        "  \n",
        "  x = residual_block(x, 64, project=True)\n",
        "  \n",
        "  for i in range(stack_amount):\n",
        "    x = residual_block(x, 64)\n",
        "    \n",
        "  x = Activation('elu')(x)\n",
        "  x = MaxPooling2D(pool_size = (2, 2), strides = (2, 2))(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(class_amount, activation = 'softmax')(x)\n",
        "  \n",
        "  return x\n",
        "\n",
        "def configure_augmented_data_generator(x_train):\n",
        "  data_generator = ImageDataGenerator(rotation_range = 5, width_shift_range = 0.15, height_shift_range = 0.15, zoom_range = 0.13, horizontal_flip = True)\n",
        "  data_generator.fit(x_train)\n",
        "  \n",
        "  return data_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4mRW2KycAF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "775b08f9-e4fb-4931-cc72-55ceff3fb4f4"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.006*8, shuffle= True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 9s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaarhmZkcCjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "24c96558-3259-45b5-d6b8-21c18cda48ce"
      },
      "source": [
        "INPUT_SHAPE = x_train.shape[1:]\n",
        "STACK_AMOUNT = 9\n",
        "CLASS_AMOUNT = 10\n",
        "\n",
        "image_input = Input(shape=INPUT_SHAPE)\n",
        "output = residual_neural_network(image_input, STACK_AMOUNT, CLASS_AMOUNT)\n",
        "ResNet = Model(image_input, output)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hiHW_iWcJw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(ResNet, strategy = tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(tpu = TPU_WORKER)))\n",
        "tpu_model.compile( optimizer = tf.train.AdamOptimizer(learning_rate = 0.002), loss = tf.keras.losses.sparse_categorical_crossentropy, metrics = ['sparse_categorical_accuracy'])\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jc51Dbac2MC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "c8e36d53-3785-42b8-a7aa-53934812c973"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "data_generator = configure_augmented_data_generator(x_train)\n",
        "ResNet.fit_generator(data_generator.flow(x_train, y_train, batch_size = 32*8), steps_per_epoch = len(x_train) / (32*8), epochs=EPOCHS, validation_data = (x_valid, y_valid))\n",
        "ResNet.evaluate(x_test, y_test, batch_size = 32*8)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c8dceabc4ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigure_augmented_data_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   batch_function = _make_execution_function(\n\u001b[0;32m--> 125\u001b[0;31m       model, mode, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;31m# Create the queue for the generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(model, mode, class_weight)\u001b[0m\n\u001b[1;32m    425\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_fit_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1924\u001b[0m     ]\n\u001b[1;32m   1925\u001b[0m     self._make_train_function_helper(\n\u001b[0;32m-> 1926\u001b[0;31m         '_fit_function', [self.total_loss] + metrics_tensors)\n\u001b[0m\u001b[1;32m   1927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'total_loss'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTWTnSsDYTMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "9e99d0c3-255f-4663-f609-7373712e3a9d"
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Flatten, Input, add, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "batch_size = 32 * 8 # *8 for the 8 TPU cores\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1, 1),\n",
        "                  padding='same',\n",
        "                  kernel_initializer='glorot_uniform')\n",
        "                  #kernel_regularizer=l2(1e-4)\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(x, filter_amount, project=False):  \n",
        "\n",
        "  if (project):#project x_input to the new dimensions\n",
        "    x_input = MaxPooling2D(pool_size = (2, 2), strides = (2, 2))(x)\n",
        "    x_input = Conv2D(filter_amount, (1, 1), strides = (1, 1))(x_input)\n",
        "    x = conv_elu_block(x, filter_amount, strides = (2, 2))\n",
        "    \n",
        "  else:\n",
        "    x_input = x\n",
        "    x = conv_elu_block(x, filter_amount)\n",
        "  \n",
        "  x = conv_elu_block(x, filter_amount)\n",
        "  \n",
        "  residual_block = add([x, x_input])\n",
        "  \n",
        "  \n",
        "  return residual_block\n",
        "  \n",
        "  \n",
        "  \n",
        "def conv_elu_block(x, filter_amount, strides = (1,1)):\n",
        "  \n",
        "  x = Conv2D(filter_amount, (3, 3), strides = strides, padding = 'same')(x)\n",
        "  x = Activation('elu')(x)\n",
        "  \n",
        "  return x\n",
        "  \n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "\n",
        "    # Start model definition.\n",
        "    filter_amount = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(16, (3, 3), strides = (1, 1), padding = 'same')(inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                x = residual_block(x, filter_amount, project = True)\n",
        "            else:\n",
        "                x = residual_block(x, filter_amount, project = False)\n",
        "        filter_amount *= 2\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = MaxPooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "  \n",
        "def configure_augmented_data_generator(x_train):\n",
        "  data_generator = ImageDataGenerator(rotation_range = 5, width_shift_range = 0.15, height_shift_range = 0.15, zoom_range = 0.13, horizontal_flip = True)\n",
        "  data_generator.fit(x_train)\n",
        "  \n",
        "  return data_generator"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o3i3vW7bIm_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8e63fe4-25cc-4b24-913a-7259d532d097"
      },
      "source": [
        "print(tensorflow.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQugPM5uYrAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2866
        },
        "outputId": "309c6671-f924-4740-9f28-97ba3ec8e4c8"
      },
      "source": [
        "model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tpu_model = tensorflow.contrib.tpu.keras_to_tpu_model(model, strategy = tensorflow.contrib.tpu.TPUDistributionStrategy(tensorflow.contrib.cluster_resolver.TPUClusterResolver(tpu = TPU_WORKER)))\n",
        "\n",
        "tpu_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001),\n",
        "              metrics=['accuracy'])\n",
        "tpu_model.summary()\n",
        "\"\"\"\n",
        "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.cifar10.load_data()\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.006*8, shuffle= True)\n",
        "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
        "\"\"\"\n",
        "EPOCHS = 200\n",
        "\n",
        "\"\"\"data_generator = configure_augmented_data_generator(x_train)\n",
        "tpu_model.fit_generator(data_generator.flow(x_train, y_train, batch_size = 32*8), epochs=EPOCHS, validation_data = (x_test, y_test))\"\"\"\n",
        "tpu_model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "tpu_model.evaluate(x_test, y_test, batch_size = 32*8)\n",
        "\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.53.89.202:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 17749368447737351137)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12912880486433505638)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 8492799238564760701)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 15717615640933417762)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 16464959520372421550)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11574764633852045627)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5491824549737591890)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 9097841645094545213)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 18240351134346038749)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16649979248019027910)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 11595269180116789044)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 32, 32, 16)   448         input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 32, 32, 16)   2320        conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 32, 32, 16)   0           conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 32, 32, 16)   2320        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 32, 32, 16)   0           conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 32, 32, 16)   0           activation_127[0][0]             \n",
            "                                                                 conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 32, 32, 16)   2320        add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 32, 32, 16)   0           conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 32, 32, 16)   2320        activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 32, 32, 16)   0           conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 32, 32, 16)   0           activation_129[0][0]             \n",
            "                                                                 add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 32, 32, 16)   2320        add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 32, 32, 16)   0           conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 32, 32, 16)   2320        activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 32, 32, 16)   0           conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 32, 32, 16)   0           activation_131[0][0]             \n",
            "                                                                 add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 16, 16, 32)   4640        add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 16, 16, 32)   0           conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 16, 16, 32)   9248        activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling2D) (None, 16, 16, 16)   0           add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 16, 16, 32)   0           conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 16, 16, 32)   544         max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 16, 16, 32)   0           activation_133[0][0]             \n",
            "                                                                 conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 16, 16, 32)   9248        add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 16, 16, 32)   0           conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 16, 16, 32)   9248        activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 16, 16, 32)   0           conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 16, 16, 32)   0           activation_135[0][0]             \n",
            "                                                                 add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 16, 16, 32)   9248        add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 16, 16, 32)   0           conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 16, 16, 32)   9248        activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 16, 16, 32)   0           conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_68 (Add)                    (None, 16, 16, 32)   0           activation_137[0][0]             \n",
            "                                                                 add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 8, 8, 64)     18496       add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 8, 8, 64)     0           conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 8, 8, 64)     36928       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling2D) (None, 8, 8, 32)     0           add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 8, 8, 64)     0           conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 8, 8, 64)     2112        max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_69 (Add)                    (None, 8, 8, 64)     0           activation_139[0][0]             \n",
            "                                                                 conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 8, 8, 64)     36928       add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 8, 8, 64)     0           conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 8, 8, 64)     36928       activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 8, 8, 64)     0           conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, 8, 8, 64)     0           activation_141[0][0]             \n",
            "                                                                 add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 8, 8, 64)     36928       add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 8, 8, 64)     0           conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 8, 8, 64)     36928       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 8, 8, 64)     0           conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_71 (Add)                    (None, 8, 8, 64)     0           activation_143[0][0]             \n",
            "                                                                 add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling2D) (None, 1, 1, 64)     0           add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 64)           0           max_pooling2d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 10)           650         flatten_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 271,690\n",
            "Trainable params: 271,690\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bff3e7ed82c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m model.fit_generator(data_generator.flow(x_train, y_train, batch_size=batch_size),\n\u001b[1;32m     65\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                         epochs=epochs, verbose=1, workers=4)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \"\"\"data_generator = configure_augmented_data_generator(x_train)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   batch_function = _make_execution_function(\n\u001b[0;32m--> 125\u001b[0;31m       model, mode, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;31m# Create the queue for the generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(model, mode, class_weight)\u001b[0m\n\u001b[1;32m    425\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_fit_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1924\u001b[0m     ]\n\u001b[1;32m   1925\u001b[0m     self._make_train_function_helper(\n\u001b[0;32m-> 1926\u001b[0;31m         '_fit_function', [self.total_loss] + metrics_tensors)\n\u001b[0m\u001b[1;32m   1927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'total_loss'"
          ]
        }
      ]
    }
  ]
}