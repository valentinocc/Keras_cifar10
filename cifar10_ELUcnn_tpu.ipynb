{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_cnn_tpu.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valentinocc/Keras_cifar10/blob/master/cifar10_ELUcnn_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfqMtqZTIueE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed May 29 10:42:05 2019\n",
        "\n",
        "@author: val\n",
        "\n",
        "basic CNN for cifar10 dataset\n",
        "\n",
        "achieves 0.889 categorical accuracy\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "%load_ext tensorboard.notebook\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import Callback\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXXTjt0dJBQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LR_adjuster(Callback):\n",
        "    '''\n",
        "    The learning rate is linearly increased from base_lr to max_lr, then linear decreased back to base_lr, and then\n",
        "    held constant at a low learning rate (min_lr) for the final epochs (Around 20-35% of epochs)\n",
        "    The idea was introduced by Leslie N. Smith in this paper: https://arxiv.org/abs/1506.01186\n",
        "    # Example\n",
        "        lra = LR_adjuster(15, min_lr = 0.002, max_lr = 0.1, base_lr = 0.04)\n",
        "        model.fit(x_train, y_train, epochs=1, batch_size=128, callbacks=[lra])\n",
        "    # Arguments\n",
        "        epochs: the amount of epochs used to train the neural network\n",
        "        base_lr: initial learning rate used in training\n",
        "        max_lr: the highest learning rate to be used in training, the learning rate will decrease after reaching this rate\n",
        "                this learning rate should be set using methods discussed in Smith's paper https://arxiv.org/pdf/1803.09820.pdf\n",
        "        min_lr: the learning rate to be used for the last 20-30% of epochs\n",
        "    '''\n",
        "\n",
        "    def __init__(self, epochs, min_lr = 0.0015, base_lr=0.01, max_lr=0.1):\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.min_lr = 0.0015\n",
        "        self.epochs_max_point = (epochs - 5) / 2\n",
        "        self.lr_step_size = (max_lr - base_lr) / self.epochs_max_point\n",
        "        self.lrs = []\n",
        "        self.lr = base_lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "        if (epoch < self.epochs_max_point):\n",
        "            self.lr = self.lr + self.lr_step_size\n",
        "        elif (epoch >= self.epochs_max_point and epoch < self.epochs_max_point * 2):\n",
        "            self.lr = self.lr - self.lr_step_size\n",
        "        else:\n",
        "            self.lr = self.min_lr\n",
        "\n",
        "        K.set_value(self.model.optimizer.lr, self.lr)\n",
        "        self.lrs.append(self.lr)\n",
        "    \n",
        "    def on_train_end(self, logs=None):\n",
        "        plt.plot( np.arange(self.epochs), self.lrs)\n",
        "        plt.show\n",
        "        print(self.lrs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCmSdbNYIzJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(input_shape):\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "    convolution_elu_dropout_block(model, 64, (3, 3), 'same', input_shape = input_shape, first_layer = True)\n",
        "    convolution_elu_dropout_block(model, 64, (3, 3), 'same')\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "    \n",
        "    convolution_elu_dropout_block(model, 128, (3, 3), 'same')\n",
        "    convolution_elu_dropout_block(model, 128, (3, 3), 'same')\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "    \n",
        "    convolution_elu_dropout_block(model, 256, (3, 3), 'same')\n",
        "    convolution_elu_dropout_block(model, 256, (3, 3), 'same')\n",
        "    convolution_elu_dropout_block(model, 256, (3, 3), 'same')\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "    \n",
        "    convolution_elu_dropout_block(model, 512, (3, 3), 'same')\n",
        "    convolution_elu_dropout_block(model, 512, (3, 3), 'same')\n",
        "    convolution_elu_dropout_block(model, 512, (3, 3), 'same')\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "    \n",
        "    convolution_elu_dropout_block(model, 512, (3, 3), 'same')\n",
        "    convolution_elu_dropout_block(model, 512, (3, 3), 'same')\n",
        "    convolution_elu_dropout_block(model, 512, (3, 3), 'same')\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "    \n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    dense_elu_block(model, 512)\n",
        "    final_dense_layer(model, 10)\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "  \n",
        "def convolution_elu_dropout_block(model, filters, filter_shape, padding_setting, input_shape = None, first_layer = False):\n",
        "\n",
        "    if (first_layer):\n",
        "        model.add(tf.keras.layers.Conv2D(filters, filter_shape, padding = padding_setting, data_format = 'channels_last', input_shape = input_shape))\n",
        "    else:\n",
        "        model.add(tf.keras.layers.Conv2D(filters, filter_shape, padding = padding_setting))\n",
        "    \n",
        "    model.add(tf.keras.layers.Activation('elu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.1))\n",
        "\n",
        "    \n",
        "    \n",
        "def dense_elu_block(model, units):\n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(units))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "    \n",
        "    \n",
        "def final_dense_layer(model, classes_amount):\n",
        "    model.add(tf.keras.layers.Dense(classes_amount))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "    \n",
        "    \n",
        "def configure_TPU_model(model):\n",
        "  \n",
        "  TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  tpu_model = tf.contrib.tpu.keras_to_tpu_model(model, strategy = tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(tpu = TPU_WORKER)))\n",
        "  tpu_model.compile( optimizer = tf.keras.optimizers.Adam(lr = 0.002), loss = tf.keras.losses.sparse_categorical_crossentropy, metrics = ['sparse_categorical_accuracy'])\n",
        "  \n",
        "  return tpu_model\n",
        "\n",
        "\n",
        "def configure_augmented_data_generator(x_train):\n",
        "  data_generator = ImageDataGenerator(rotation_range = 5, width_shift_range = 0.15, height_shift_range = 0.15, zoom_range = 0.13, horizontal_flip = True)\n",
        "  data_generator.fit(x_train)\n",
        "  \n",
        "  return data_generator "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnjT3HIFI2nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.006*8, shuffle= True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ODf825uM8Fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "keras_model = model(input_shape)\n",
        "\n",
        "#create TensorBoard callback\n",
        "logdir=\"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "tpu_model = configure_TPU_model(keras_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmJ39OFxWYI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 150\n",
        "\n",
        "data_generator = configure_augmented_data_generator(x_train)\n",
        "lra = LR_adjuster(EPOCHS, min_lr = 0.002, max_lr = 0.01, base_lr = 0.001)\n",
        "tpu_model.fit_generator(data_generator.flow(x_train, y_train, batch_size = 32 * 8), steps_per_epoch = len(x_train) / (32 * 8), epochs=EPOCHS, validation_data = (x_valid, y_valid), callbacks = [tensorboard])\n",
        "tpu_model.evaluate(x_test, y_test, batch_size = 32*8)\n",
        "tpu_model.save_weights('./tpu_model_weights.h5', overwrite = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZPGFdAN-Dnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}